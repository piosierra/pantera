#!/usr/bin/env Rscript

version <- "0.0.5"




### To Do

# Dynamical bands
# Select bands to process
# Merge exits
# Classifier
# Fix: Include correct name of path
# Improvement: accept compressed gfas
# Improvement: fix some variable names


## For slurm
# local({r <- getOption("repos")
# r["CRAN"] <- "https://cran.r-project.org"
# options(repos = r)
# })
# .libPaths(c("~/R/4.2.2", .libPaths()))

## Libraries
if (!require("data.table", quietly = TRUE)) {
  install.packages("data.table")
}
if (!require("kmer", quietly = TRUE)) {
  install.packages("kmer")
}
if (!require("getopt", quietly = TRUE)) {
  install.packages("getopt")
}
if (!require("parallel", quietly = TRUE)) {
  install.packages("parallel")
}
if (!require("ips", quietly = TRUE)) {
  install.packages("ips")
}
if (!require("stringr", quietly = TRUE)) {
  install.packages("stringr")
}
if (!require("BiocManager", quietly = TRUE)) {
  install.packages("BiocManager")
}
if (!require("Biostrings", quietly = TRUE)) {
  BiocManager::install("Biostrings")
}
if (!require("bioseq", quietly = TRUE)) {
  BiocManager::install("bioseq")
}
if (!require("ggplot2", quietly = TRUE)) {
  install.packages("ggplot2")
}

## Reading args
spec <- matrix(
  c(
    "gfas_list",          "g", 1, "character",
    "identity",           "i", 1, "integer",
    "min_cl",             "m", 1, "integer",
    "cl_size",            "c", 1, "integer",
    "output_folder",      "o", 1, "character",
    "min_size",           "s", 1, "integer",
    "max_size",           "l", 1, "integer",
    "max_pairs",          "p", 1, "integer",
    "help",               "h", 0, "logical"
  ),
  byrow = TRUE,
  ncol = 4
)
opt <- getopt(spec)

if (!is.null(opt$help)) {
  cat(getopt(spec, usage = TRUE))
  q(status = 1)
}

if (is.null(opt$gfas_list)) {
  print("-gfas_list missing")
  q(status <- 1)
}

if (is.null(opt$output_folder)) {
  print("-output_folder missing")
  q(status <- 1)
}

if (is.null(opt$min_size)) { # Minimun size of TE
  opt$min_size <- 200
}

if (is.null(opt$max_size)) { # Maximum size of TE
  opt$max_size <- 20000
}

if (is.null(opt$max_pairs)) { # Maximum number of paths pairs to examine
  opt$max_pairs <- Inf
}

if (is.null(opt$identity)) { # Minimum identity for clustering
  opt$identity <- 97
}

if (is.null(opt$min_cl)) { # Minimium number of segments to create a consensus
  opt$min_cl <- 2
}

if (is.null(opt$cl_size)) { # Maximum size of cluster to process
  opt$cl_size <- 300
}

## Auxiliary function to convert from dna to binDNA format
reformatDNA <- function(dna) {
  temp <- matrix(as.character(dna),
    nrow = (length(row.names(dna))),
    dimnames = dimnames(dna)
  )
  temp <- dna(apply(temp, 1, function(x) {
    paste0(x, collapse = "")
  }))
  return(temp)
}

# @ Auxiliary function for log exits
lx <- function(x) {
#  print(paste0(format(Sys.time(), "%H:%M:%S"), " [pantera ", version, "] ", x))
  cat(paste0(format(Sys.time(), "%y-%m-%d:%H:%M:%S"), " \033[95;1;1m[pantera ", version, "]\033[0m ", x, "\n"))
}


### MAIN

## Confirm mafft is available
mafft_exec <- system("which mafft", intern = TRUE)
if (length(grep("mafft", mafft_exec)) > 0) {
  print(paste("mafft exec:", mafft_exec))
} else {
  lx("mafft not found")
  stop()
}

## DF to store unique segments
segments_unique <- data.table(
  path = as.character(),
  seg = as.character(),
  seq = as.character()
)


## Main loop
lx(paste("pantera", version))
lx(paste("Cores available:", detectCores()))
lx(paste("Gfas list:", opt$gfas_list))
lx(paste("Output:", opt$output_folder))
lx(paste("Min. size:", opt$min_size))
lx(paste("Max. size:", opt$max_size))
lx(paste("Paths pairs to examine:", opt$max_pairs))
lx(paste("Identity for clustering:", opt$identity))
lx(paste("Min. sequences to create a consensus:", opt$min_cl))
lx(paste("Sequences to cluster by batch:", opt$cl_size))


## Extract unique segements
pair <- 0 # counter for opt$max_pairs, probably should have another name. Changed to pair
for (g in read.table(opt$gfas_list)$V1) {
  segments <- fread(cmd = paste0("grep \"^S\" ", g), header = FALSE)
  segments <- segments[, c(1:3)]
  colnames(segments) <- c("tag","seg","seq")
  lx(paste("Number of segments =", nrow(segments)))
  paths <- fread(cmd = paste0("grep \"^P\" ", g), header = FALSE)
  lx(paste("Number of paths =", nrow(paths)))
  paths_s <- mclapply(
    paths$V3,
    function(x) {
      as.numeric(gsub(
        "-", "",
        gsub(
          "\\+", "",
          strsplit(x, ",")[[1]]
        )
      ))
    }
  )
  for (i in 1:(length(paths_s) - 1)) {
    for (j in (i + 1):length(paths_s)) {
      pair <- pair + 1
      if (pair > opt$max_pairs) break
      lx(paste("Paths:", paths$V2[i], "<->", paths$V2[j]))
      if ((sum(unique(paths_s[i][[1]]) %in% unique(paths_s[j][[1]])) /
        min(length(unique(paths_s[i][[1]])), length(unique(paths_s[j][[1]]))))
      > 0.3) {  # Magic number. Make paramether.
        p1 <- unique(paths_s[i][[1]])
        p2 <- unique(paths_s[j][[1]])
        pt <- unique(c(p1, p2))
        data <- data.table(seg = pt)
        data[, new := (seg %in% p1)+2*(seg %in% p2)]
        segments_path <- merge(segments, data[new<3])
        segments_path[new==1,path:=paths$V2[i]]
        segments_path[new==2,path:=paths$V2[j]]
        lx(paste("Unique segments:", nrow(segments_path)))
        segments_unique <- rbindlist(list(segments_unique, segments_path[,c("path","seg","seq")]))
      }
    }
  }
}
lx(paste("TOTAL Unique segments:", nrow(segments_unique)))
segments_unique <- segments_unique[!duplicated(segments_unique$seg)]
lx(paste("TOTAL Unique segments no dups:", nrow(segments_unique)))
segments_unique[, Ns := str_count(segments_unique$seq, "N")]
segments_unique[, len := nchar(seq)]
segments_unique[, name := paste0(">", segments_unique$path, "_", segments_unique$seg)]
segments_unique <- segments_unique[len >= opt$min_size &
  len <= opt$max_size &
  Ns < len * 0.05]  # Magic number. Make paramether.
segments_unique <- segments_unique[order(len)]
lx(paste("TOTAL Unique segments purged:", nrow(segments_unique)))

dir.create(opt$output_folder, showWarnings = FALSE)
setwd(opt$output_folder)

fileConn <- file("all_segments.fa")
writeLines(t(segments_unique[, c("name","seq")]), fileConn)
close(fileConn)

## List of the bands to look for TEs. Should include a way to choose them.
# zones <- list(
#   c(200, 300), c(300, 500), c(500, 1000), c(1000, 2000), c(2000, 4000),
#   c(4000, 6000), c(6000, 8000), c(8000, 13000), c(13000, 20000)
# )
zones <- rev(lapply(levels(cut_number(segments_unique$len,detectCores())), 
                 function(x){ c(as.numeric(gsub("Â·*[\\(|\\[]","",gsub(",.*","",x))),
                                as.numeric(gsub(".*,","",gsub("\\].*","",x))))}))


## Generate consensus from the unique segments for each "zone"
process_zone <- function(zone) {
  start <- zone[1]
  end <- zone[2]
  lx(paste("Procesing segments:", start, "-", end))
  segment_u <- segments_unique[len > start & len < end]

  ## Divide each zone in subsets if segments larger than
  segment_sets <- split(segment_u, (1:nrow(segment_u)) %/% opt$cl_size)
  lx(paste("Segment sets", start, "-", end, ":", length(segment_sets)))
  for (ss in 1:length(segment_sets)) {
    sg <- segment_sets[[ss]]
    der <- strsplit(sg$seq, "")
    names(der) <- sg$name
    sol <- otu(der, k = 7, threshold = opt$identity / 100, nstart = 10)
  #  sol_rep <- sol[sol %in% sol[grep("\\*", names(sol), invert = T)]][grep("\\*", names(sol[sol %in% sol[grep("\\*", names(sol), invert = T)]]))]
 #   table(sol[sol %in% sol_rep])[table(sol[sol %in% sol_rep]) >= opt$min_cl]
 #   sol_list <- sol[sol %in% sol_rep]
    sol_list <- sol[sol %in% names(table(sol)[table(sol)>=opt$min_cl])]
    lx(paste("# of clusters ", start, "-", end, "-", ss, ":", length(unique(sol_list))))
    names(sol_list) <- gsub("\\*", "", names(sol_list))
    data_sol <- data.table(
 #     name = gsub(".*:", "", names(sol_list)),
      name = names(sol_list),
      cluster = sol_list
    )
    consensi <- data.table(name = as.character(), seq = as.character())
    for (u in unique(data_sol$cluster)) {
      clust_temp <- strsplit(sg[name %in% data_sol[cluster == u]$name]$seq, "")
      names(clust_temp) <- sg[name %in% data_sol[cluster == u]$name]$name
      seqs <- as.DNAbin(clust_temp)
      ali <- mafft(seqs, thread = -1, exec = mafft_exec)
      cons <- seq_consensus(dna(reformatDNA(ali)), 
                            method = "chr_ambiguity") # can be gaps = F
      consensi <- rbindlist(list(
        consensi,
        data.table(
          name = gsub(".>.","#",paste0(data_sol[cluster == u]$name,collapse="")),
          seq = gsub("-", "", as.character(cons))
        )
      ))
    }
    fileconn <- file(paste0("consensi_", start, "_", end, "-", ss, ".fa"))
    writeLines(t(consensi), fileconn)
    close(fileconn)
  }
  lx(paste("Zone:", zone[2], "completed."))
  return(0)
}

end <- mclapply(zones, process_zone)
if (unique(end)!=0) {
  lx("Some zones reported errors")
} else {
  lx("All zones processed.")
}
